{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer_Vision_Team_Project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sswon314/CV_Colorization/blob/master/Computer_Vision_Team_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgaJh-BaTStR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gDrive\")\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "Qmh1iGMLTvo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img"
      ],
      "metadata": {
        "id": "KxiJtQlg04by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform (이미지 변환)"
      ],
      "metadata": {
        "id": "_jrAjnafUQCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorHintTransform(object):\n",
        "    def __init__(self, size=256, mode=\"train\"):\n",
        "        super(ColorHintTransform, self).__init__()\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def bgr_to_lab(self, img):\n",
        "        # rgb 값을 lab로 변경\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        # l은 명도(gray), ab는 채색?인듯\n",
        "        l, ab = lab[:, :, 0], lab[:, :, 1:]\n",
        "        return l, ab\n",
        "\n",
        "    def hint_mask(self, bgr, threshold=[0.95, 0.97, 0.99]):\n",
        "        h, w, c = bgr.shape\n",
        "        mask_threshold = random.choice(threshold)\n",
        "        # h*w*1 크기의 매트릭스에 T or F로 (랜덤값이 threshold보다 크면 T)\n",
        "        mask = np.random.random([h, w, 1]) > mask_threshold \n",
        "        return mask\n",
        "\n",
        "    def img_to_mask(self, mask_img):\n",
        "        mask = mask_img[:, :, 0, np.newaxis] >= 255\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, img, mask_img=None):\n",
        "        threshold = [0.95, 0.97, 0.99]\n",
        "        if (self.mode == \"train\") | (self.mode == \"val\"):\n",
        "            image = cv2.resize(img, (self.size, self.size))\n",
        "            mask = self.hint_mask(image, threshold)\n",
        "\n",
        "            # hint mask에서 true 인 부분의 픽셀만 값을 가짐\n",
        "            hint_image = image * mask\n",
        "\n",
        "            # 이미지의 l, ab값 추출\n",
        "            # 힌트 이미지(특정 픽셀만 보이는 이미지)의 l, ab값 추출\n",
        "            l, ab = self.bgr_to_lab(image)\n",
        "            l_hint, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "            # 각각의 값을 tensor로 변환해서 반환\n",
        "            return self.transform(l), self.transform(ab), self.transform(ab_hint), self.transform(mask)\n",
        "\n",
        "        elif self.mode == \"test\":\n",
        "            image = cv2.resize(img, (self.size, self.size))\n",
        "            mask = self.img_to_mask(mask_img)\n",
        "            hint_image = image * mask\n",
        "\n",
        "            l, _ = self.bgr_to_lab(image)\n",
        "            _, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "            return self.transform(l), self.transform(ab_hint), self.transform(mask)\n",
        "\n",
        "        else:\n",
        "            return NotImplementedError"
      ],
      "metadata": {
        "id": "NOjxJnclURZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Unzip"
      ],
      "metadata": {
        "id": "jAXFHtBSTzt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 드라이브에 있는 데이터 zip 파일 압축 해제\n",
        "\n",
        "# Train, Val 데이터 압축해제\n",
        "trainFileName=\"colorization_dataset.zip\"\n",
        "trainZipPath=\"/content/gDrive/MyDrive/CV/colorization_dataset.zip\"\n",
        "\n",
        "# zip path에 있는 현재 디렉토리에 복사 -> 압축해제 -> 복사한 zip파일 삭제\n",
        "!cp \"{trainZipPath}\" .\n",
        "!unzip -q \"{trainFileName}\"\n",
        "!rm \"{trainFileName}\"\n",
        "\n",
        "\n",
        "# Test 데이터 압축해제\n",
        "testFileName=\"test_dataset.zip\"\n",
        "testZipPath=\"/content/gDrive/MyDrive/CV/test_dataset.zip\"\n",
        "\n",
        "# zip path에 있는 현재 디렉토리에 복사 -> 압축해제 -> 복사한 zip파일 삭제\n",
        "!cp \"{testZipPath}\" .\n",
        "!unzip -q \"{testFileName}\" -d \"cv_project\"\n",
        "!rm \"{testFileName}\"\n",
        "\n",
        "\n",
        "# 압축 해제 후 디렉토리\n",
        "# cv_project\n",
        "#   └ train\n",
        "#   └ val\n",
        "#   └ test_dataset\n",
        "#       └ hint\n",
        "#       └ mask"
      ],
      "metadata": {
        "id": "MwvE0zYaV25R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "id": "lBIFlX_534EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = \"cv_project\"\n",
        "train_dir = os.path.join(root_path, \"train\")\n",
        "examples = [os.path.join(root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "\n",
        "print(\"Before Augmentation: {}\".format(len(examples)))\n",
        "for f in examples:\n",
        "    file = cv2.imread(f)\n",
        "    file = cv2.cvtColor(file , cv2.COLOR_BGR2RGB)\n",
        "    conv_file = cv2.flip(file,1)\n",
        "    rot_file = cv2.rotate(file , cv2.ROTATE_180)\n",
        "    cv2.imwrite(os.path.join(train_dir, 'flip_image{}.png'.format(examples.index(f))), conv_file)\n",
        "    cv2.imwrite(os.path.join(train_dir, 'rot_image{}.png'.format(examples.index(f))),rot_file)\n",
        "\n",
        "examples = [os.path.join(root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "print(\"After Augmentation: {}\".format(len(examples)))"
      ],
      "metadata": {
        "id": "5tHocbL_Wv3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "okK449lmtgrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorHintDataset(data.Dataset):\n",
        "    def __init__(self, root_path, size, mode=\"train\"):\n",
        "        super(ColorHintDataset, self).__init__()\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "        self.transforms = ColorHintTransform(self.size, self.mode)\n",
        "        self.examples = None\n",
        "        self.hint = None\n",
        "        self.mask = None\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            train_dir = os.path.join(self.root_path, \"train\")\n",
        "            self.examples = [os.path.join(self.root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "        elif self.mode == \"val\":\n",
        "            val_dir = os.path.join(self.root_path, \"val\")\n",
        "            self.examples = [os.path.join(self.root_path, \"val\", dirs) for dirs in os.listdir(val_dir)]\n",
        "        elif self.mode == \"test\":\n",
        "            hint_dir = os.path.join(self.root_path, \"test_dataset/hint\")\n",
        "            mask_dir = os.path.join(self.root_path, \"test_dataset/mask\")\n",
        "            self.hint = [os.path.join(self.root_path, \"test_dataset/hint\", dirs) for dirs in os.listdir(hint_dir)]\n",
        "            self.mask = [os.path.join(self.root_path, \"test_dataset/mask\", dirs) for dirs in os.listdir(mask_dir)]\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.mode != \"test\":\n",
        "            return len(self.examples)\n",
        "        else:\n",
        "            return len(self.hint)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == \"test\":\n",
        "            hint_file_name = self.hint[idx]\n",
        "            mask_file_name = self.mask[idx]\n",
        "            hint_img = cv2.imread(hint_file_name)\n",
        "            mask_img = cv2.imread(mask_file_name)\n",
        "\n",
        "            input_l, input_hint, mask = self.transforms(hint_img, mask_img)\n",
        "            sample = {\"l\": input_l, \"hint\": input_hint, \"mask\": mask,\n",
        "                      \"file_name\": \"image_%06d.png\" % int(os.path.basename(hint_file_name).split('.')[0])}\n",
        "        else:\n",
        "            file_name = self.examples[idx]\n",
        "            img = cv2.imread(file_name)\n",
        "            l, ab, hint, mask = self.transforms(img)\n",
        "            sample = {\"l\": l, \"ab\": ab, \"hint\": hint, \"mask\": mask}\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "uny_mLAXTxW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서를 이미지로 변환\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "    if isinstance(input_image, torch.Tensor):\n",
        "        image_tensor = input_image.data\n",
        "    else:\n",
        "        return input_image\n",
        "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "    if image_numpy.shape[0] == 1:\n",
        "        image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "    image_numpy = np.clip((np.transpose(image_numpy, (1, 2, 0))), 0, 1) * 255.0\n",
        "    return image_numpy.astype(imtype)\n",
        "\n",
        "\n",
        "# Change to your data root directory\n",
        "root_path = \"cv_project\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "# use_cuda = torch.cuda.is_available()\n",
        "\n",
        "train_dataset = ColorHintDataset(root_path, 256, \"train\")\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "val_dataset = ColorHintDataset(root_path, 256, \"val\")\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "test_dataset = ColorHintDataset(root_path, 256, \"test\")\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "print('train dataset length:' , len(train_dataloader)) \n",
        "print('val dataset length: ', len(val_dataloader))\n",
        "print('test dataset length: ', len(test_dataloader))"
      ],
      "metadata": {
        "id": "dWDcJUhyUVbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "V_oTawNUUUFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network"
      ],
      "metadata": {
        "id": "fLvD39aNs5iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/LeeJunHyun/Image_Segmentation\n",
        "class up_conv(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out):\n",
        "        super(up_conv,self).__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
        "\t\t        nn.BatchNorm2d(ch_out),\n",
        "\t\t\t      nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(ch_out , ch_out , 3,2,1,1),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "\t\t\t      nn.ReLU(inplace=True),\n",
        "         )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "class Recurrent_block(nn.Module):\n",
        "    def __init__(self,ch_out):\n",
        "        super(Recurrent_block,self).__init__()\n",
        "        self.ch_out = ch_out\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
        "\t\t        nn.BatchNorm2d(ch_out),\n",
        "\t\t\t      nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "      x1 = self.conv(x)\n",
        "      return x1\n",
        "\n",
        "class Attention_block(nn.Module):\n",
        "    def __init__(self,F_g,F_l,F_int):\n",
        "        super(Attention_block,self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        \n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    def forward(self,g,x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1+x1)\n",
        "        psi = self.psi(psi)\n",
        "\n",
        "        return x*psi\n",
        "\n",
        "class RRCNN_block(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out):\n",
        "        super(RRCNN_block,self).__init__()\n",
        "        self.RCNN = nn.Sequential(\n",
        "            Recurrent_block(ch_out),\n",
        "            Recurrent_block(ch_out)\n",
        "        )\n",
        "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.Conv_1x1(x)\n",
        "        x1 = self.RCNN(x)\n",
        "        return x+x1\n",
        "\n",
        "class R2AttU_Net(nn.Module):\n",
        "    def __init__(self,img_ch=4,output_ch=3,t=2):\n",
        "        super(R2AttU_Net,self).__init__()\n",
        "        \n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.Upsample = nn.Upsample(scale_factor=2)\n",
        "\n",
        "        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64)\n",
        "\n",
        "        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128)\n",
        "        \n",
        "        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256)\n",
        "        \n",
        "        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512)\n",
        "        \n",
        "        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024)\n",
        "        \n",
        "\n",
        "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
        "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
        "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512)\n",
        "        \n",
        "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
        "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
        "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256)\n",
        "        \n",
        "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
        "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
        "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128)\n",
        "        \n",
        "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
        "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
        "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        # encoding path\n",
        "        x1 = self.RRCNN1(x)\n",
        "\n",
        "        x2 = self.Maxpool(x1)\n",
        "        x2 = self.RRCNN2(x2)\n",
        "        \n",
        "        x3 = self.Maxpool(x2)\n",
        "        x3 = self.RRCNN3(x3)\n",
        "\n",
        "        x4 = self.Maxpool(x3)\n",
        "        x4 = self.RRCNN4(x4)\n",
        "\n",
        "        x5 = self.Maxpool(x4)\n",
        "        x5 = self.RRCNN5(x5)\n",
        "\n",
        "        # decoding + concat path\n",
        "        d5 = self.Up5(x5)\n",
        "        x4 = self.Att5(g=d5,x=x4)\n",
        "        d5 = torch.cat((x4,d5),dim=1)\n",
        "        d5 = self.Up_RRCNN5(d5)\n",
        "        \n",
        "        d4 = self.Up4(d5)\n",
        "        x3 = self.Att4(g=d4,x=x3)\n",
        "        d4 = torch.cat((x3,d4),dim=1)\n",
        "        d4 = self.Up_RRCNN4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        x2 = self.Att3(g=d3,x=x2)\n",
        "        d3 = torch.cat((x2,d3),dim=1)\n",
        "        d3 = self.Up_RRCNN3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        x1 = self.Att2(g=d2,x=x1)\n",
        "        d2 = torch.cat((x1,d2),dim=1)\n",
        "        d2 = self.Up_RRCNN2(d2)\n",
        "\n",
        "        d1 = self.Conv_1x1(d2)\n",
        "\n",
        "        return d1"
      ],
      "metadata": {
        "id": "hoQXcop44BzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "PK97kzHOG9Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 결과 저장 위치\n",
        "# 훈련 결과 저장 위치는 드라이브에 설정해서 나중에 불러와서 쓸 수 있도록 함\n",
        "save_path = '/content/gDrive/MyDrive/CV'\n",
        "os.makedirs(save_path, exist_ok= True)\n",
        "best_output_path = os.path.join(save_path, 'best_model.tar')  # 가장 좋은 성능 모델\n",
        "last_output_path = os.path.join(save_path, 'last_model.tar')  # 마지막으로 학습한 모델\n",
        "\n",
        "### 하이퍼파라미터 ###\n",
        "# 한번에 학습할 epoch수\n",
        "EPOCH=200\n",
        "LR = 0.00025\n",
        "\n",
        "# 모델 설정\n",
        "trainNet = R2AttU_Net().cuda()\n",
        "\n",
        "# loss function 및 optimizer 설정\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(trainNet.parameters(), lr=LR)\n",
        "\n",
        "\n",
        "# 이전에 학습했던 모델이 있으면 그 모델의 weight값으로 설정\n",
        "if os.path.isfile(last_output_path):\n",
        "  print(\"체크포인트 불러옴\")\n",
        "  checkpoint_dict=torch.load(last_output_path)\n",
        "  train_info = checkpoint_dict[\"train_info\"]\n",
        "  val_info = checkpoint_dict[\"val_info\"]\n",
        "  best_loss = checkpoint_dict[\"best_loss\"]\n",
        "  start_epoch = checkpoint_dict[\"epoch\"]+1\n",
        "  print(\"Epoch {}번부터 시작\".format(start_epoch))\n",
        "\n",
        "  trainNet.load_state_dict(checkpoint_dict['model_weight'])\n",
        "\n",
        "  epochAxis=np.arange(0, len(checkpoint_dict[\"train_info\"]))\n",
        "\n",
        "  plt.title(\"LOSS\")\n",
        "  plt.plot(epochAxis, [info[\"loss\"].cpu() for info in checkpoint_dict[\"train_info\"]], epochAxis, [info[\"loss\"].cpu() for info in checkpoint_dict[\"val_info\"]], \"r-\")\n",
        "  plt.legend([\"TRAIN\",\"VALIDATION\"])\n",
        "  plt.show()\n",
        "\n",
        "# 없으면 기본 값 사용\n",
        "else:\n",
        "  print(\"체크포인트 없음\")\n",
        "  train_info=[]\n",
        "  val_info=[]\n",
        "  best_loss = 100\n",
        "  start_epoch=0"
      ],
      "metadata": {
        "id": "H17r5Wu2GXfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training 시킬 함수\n",
        "def train_model(net, train_dataloader):\n",
        "  total_loss = 0\n",
        "  iteration = 0\n",
        "  net.train()\n",
        "\n",
        "  for i, data in enumerate(tqdm.auto.tqdm(train_dataloader)):\n",
        "    if use_cuda:\n",
        "      l_imgs = data[\"l\"].to('cuda')\n",
        "      ab_imgs = data[\"ab\"].to('cuda')\n",
        "      hint_imgs = data[\"hint\"].to('cuda')\n",
        "      mask_imgs = data[\"mask\"].to('cuda')\n",
        "    else:\n",
        "      l_imgs = data[\"l\"]\n",
        "      ab_imgs = data[\"ab\"]\n",
        "      hint_imgs = data[\"hint\"]\n",
        "      mask = data[\"mask\"]\n",
        "\n",
        "    gt_image = torch.cat((l_imgs,ab_imgs), dim=1)\n",
        "    hint_image = torch.cat((l_imgs, hint_imgs, mask_imgs), dim=1)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    output = net(hint_image)\n",
        "\n",
        "    loss = criterion(output, gt_image)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    total_loss += loss.detach()\n",
        "    iteration += 1\n",
        "  \n",
        "  total_loss /= iteration\n",
        "  return total_loss\n",
        "\n",
        "# Validation 시킬 함수\n",
        "def val_model(net, val_dataloader):\n",
        "  total_loss = 0\n",
        "  iteration = 0\n",
        "  net.eval()\n",
        "\n",
        "  for i, data in enumerate(tqdm.auto.tqdm(val_dataloader)):\n",
        "    if use_cuda:\n",
        "      l_imgs = data[\"l\"].to('cuda')\n",
        "      ab_imgs = data[\"ab\"].to('cuda')\n",
        "      hint_imgs = data[\"hint\"].to('cuda')\n",
        "      mask_imgs = data[\"mask\"].to('cuda')\n",
        "    else:\n",
        "      l_imgs = data[\"l\"]\n",
        "      ab_imgs = data[\"ab\"]\n",
        "      hint_imgs = data[\"hint\"]\n",
        "\n",
        "    gt_image = torch.cat((l_imgs,ab_imgs), dim=1)\n",
        "    hint_image = torch.cat((l_imgs, hint_imgs, mask_imgs), dim=1)\n",
        "   \n",
        "    output = net(hint_image).squeeze(1)\n",
        "\n",
        "    loss = criterion(output, gt_image)\n",
        "\n",
        "    total_loss += loss.detach()\n",
        "    iteration += 1\n",
        "\n",
        "  total_loss /= iteration\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "r0PotxZbhtEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전 학습 모델의 다음 epoch부터 n번 실행\n",
        "for epoch in range(start_epoch,start_epoch+EPOCH):\n",
        "  t_loss = train_model(trainNet, val_dataloader)\n",
        "  print('[TRAINING] Epoch: {} train_loss: {}'.format(epoch, t_loss))\n",
        "  train_info.append({'loss': t_loss})\n",
        "\n",
        "  with torch.no_grad():\n",
        "    v_loss = val_model(trainNet, val_dataloader)\n",
        "    print('[VALIDATION] Epoch: {} validation_loss: {}'.format(epoch, v_loss))\n",
        "    val_info.append({'loss': v_loss})\n",
        "  \n",
        "  # 검증 loss가 제일 모델 저장\n",
        "  if best_loss > v_loss:\n",
        "    best_loss = v_loss\n",
        "    print(\"최고 성능 모델 저장\")\n",
        "    torch.save({\n",
        "      \"memo\": \"This is Best Model\",\n",
        "      \"epoch\": epoch,\n",
        "      \"best_loss\": best_loss,\n",
        "      \"model_weight\":trainNet.state_dict()\n",
        "    }, best_output_path)\n",
        "\n",
        "  # 해당 epoch에 대한 모델 저장\n",
        "  print(\"{}번째 모델 저장\".format(epoch))\n",
        "  torch.save({\n",
        "      \"memo\": \"This is Last Model\",\n",
        "      \"epoch\": epoch,\n",
        "      \"best_loss\": best_loss,\n",
        "      \"train_info\":train_info,\n",
        "      \"val_info\":val_info,\n",
        "      \"model_weight\":trainNet.state_dict(),\n",
        "  }, last_output_path)"
      ],
      "metadata": {
        "id": "_t2LjOkv9Fy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "3TTzbyFw8f6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 시킬 함수\n",
        "def test_model(net, test_dataloader):\n",
        "  net.eval()\n",
        "  for i, data in enumerate(tqdm.auto.tqdm(test_dataloader)):\n",
        "    if use_cuda:\n",
        "        l = data[\"l\"].to('cuda')\n",
        "        hint = data[\"hint\"].to('cuda')\n",
        "        mask = data[\"mask\"].to('cuda')\n",
        "    else:\n",
        "        l = data[\"l\"]\n",
        "        hint = data[\"hint\"]\n",
        "        mask = data[\"mask\"]\n",
        "\n",
        "    hint_image = torch.cat((l, hint, mask), dim=1)\n",
        "\n",
        "    output = net(hint_image).squeeze(1)\n",
        "    output_np = tensor2im(output)\n",
        "\n",
        "    output_bgr = cv2.cvtColor(output_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # 결과 이미지 저장 (제출용)\n",
        "    os.makedirs('cv_project/outputs/', exist_ok=True) \n",
        "    i = str(i).zfill(6)\n",
        "    cv2.imwrite('cv_project/outputs/' + data['file_name'][0], output_bgr)\n",
        "\n",
        "    # 결과 이미지를 보여줌\n",
        "    plt.imshow(output_bgr)\n",
        "    plt.show()\n",
        "\n",
        "    # 아무 값이나 입력해서 다음 이미지 표시\n",
        "    # input 빼면 자동 저장\n",
        "    # input()"
      ],
      "metadata": {
        "id": "1-UjqGbAx0zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "save_path = '/content/gDrive/MyDrive/CV'\n",
        "last_model_path = os.path.join(save_path, 'last_model.tar')\n",
        "best_model_path = os.path.join(save_path, 'best_model.tar')\n",
        "\n",
        "if os.path.isfile(last_model_path):\n",
        "  last_state_dict=torch.load(last_model_path)\n",
        "  print(\"Epoch {}까지 돌렸음\".format(last_state_dict[\"epoch\"]))\n",
        "  epochAxis=np.arange(0, len(last_state_dict[\"train_info\"]))\n",
        "\n",
        "  plt.title(\"LOSS\")\n",
        "  plt.plot(epochAxis, [info[\"loss\"].cpu() for info in last_state_dict[\"train_info\"]], epochAxis, [info[\"loss\"].cpu() for info in last_state_dict[\"val_info\"]], \"r-\")\n",
        "  plt.legend([\"TRAIN\",\"VALIDATION\"])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "if os.path.isfile(best_model_path):\n",
        "  best_state_dict=torch.load(best_model_path)\n",
        "  print(\"Epoch {}일때 최고 성능이었음\".format(best_state_dict[\"epoch\"]))\n",
        "\n",
        "  testNet = R2AttU_Net().cuda()\n",
        "\n",
        "  testNet.load_state_dict(best_state_dict['model_weight'])\n",
        "\n",
        "  test_model(testNet, test_dataloader)"
      ],
      "metadata": {
        "id": "jn8E95UV9HRP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}